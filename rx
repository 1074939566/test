import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
import numpy as np
import time
from collections import defaultdict
from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction
import matplotlib.pyplot as plt

# 配置参数
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 数据预处理函数
def tokenize_zh(text):
    return list(text.strip())

def tokenize_en(text):
    return text.strip().lower().split()

def build_vocab(sentences, tokenizer, max_size=20000, min_freq=1):
    vocab = defaultdict(int)
    for sent in sentences:
        for token in tokenizer(sent):
            vocab[token] += 1
    sorted_vocab = sorted(vocab.items(), key=lambda x: -x[1])
    vocab_dict = {'<pad>':0, '<unk>':1, '<sos>':2, '<eos>':3}
    idx = 4
    for token, count in sorted_vocab:
        if idx >= max_size or count < min_freq:
            break
        vocab_dict[token] = idx
        idx += 1
    return vocab_dict

# 加载数据
with open('WikiTitles.en-zh.en', 'r', encoding='utf-8') as f:
    zh_sents = [line.strip() for line in f][:100000]
with open('WikiTitles.en-zh.zh', 'r', encoding='utf-8') as f:
    en_sents = [line.strip() for line in f][:100000]

# 构建词汇表
src_vocab = build_vocab(zh_sents, tokenize_zh)
trg_vocab = build_vocab(en_sents, tokenize_en)

# 数值化处理
def numericalize(sentence, vocab, tokenizer):
    return [vocab.get(t, vocab['<unk>']) for t in tokenizer(sentence)]

# 得到每一行的数列表，比如for s in zh_sents到第八行计算机科学，会得到[2, 4, 5, 6, 7, 8, 3]而整个src_data就是嵌套列表
src_data = [
    [src_vocab['<sos>']] + numericalize(s, src_vocab, tokenize_zh) + [src_vocab['<eos>']]
    for s in zh_sents
]
trg_data = [
    [trg_vocab['<sos>']] + numericalize(s, trg_vocab, tokenize_en) + [trg_vocab['<eos>']]
    for s in en_sents
]

# 划分数据集
train_src, val_src, train_trg, val_trg = train_test_split(
    src_data, trg_data, test_size=0.1, random_state=SEED)

# 数据加载器
class TranslationDataset(Dataset):
    def __init__(self, src, trg):
        self.src = src
        self.trg = trg
        
    def __getitem__(self, idx):
        return {'src': torch.LongTensor(self.src[idx]),
                'trg': torch.LongTensor(self.trg[idx])}
    
    def __len__(self):
        return len(self.src)

def collate_fn(batch):
    src = [item['src'] for item in batch]
    trg = [item['trg'] for item in batch]
    return {
        'src': torch.nn.utils.rnn.pad_sequence(src, padding_value=0).to(device),
        'trg': torch.nn.utils.rnn.pad_sequence(trg, padding_value=0).to(device)
    }

BATCH_SIZE = 128
train_loader = DataLoader(TranslationDataset(train_src, train_trg), 
                         batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)
val_loader = DataLoader(TranslationDataset(val_src, val_trg),
                       batch_size=BATCH_SIZE, collate_fn=collate_fn)

# 模型定义（修正维度对齐问题）
class Encoder(nn.Module):
    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):
        super().__init__()
        self.embedding = nn.Embedding(input_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True)
        #self.fc_hidden = nn.Linear(hid_dim*2, hid_dim)
        #self.fc_cell = nn.Linear(hid_dim*2, hid_dim)
        
    def forward(self, src):
        embedded = self.embedding(src)
        outputs, (hidden, cell) = self.rnn(embedded)
        # 合并双向LSTM的hidden states
        hidden = hidden.view(self.rnn.num_layers, 2, -1, self.rnn.hidden_size)
        hidden = torch.cat([hidden[:,0,:,:], hidden[:,1,:,:]], dim=2)
        #hidden = self.fc_hidden(hidden)
        cell = cell.view(self.rnn.num_layers, 2, -1, self.rnn.hidden_size)
        cell = torch.cat([cell[:,0,:,:], cell[:,1,:,:]], dim=2)
        #cell = self.fc_cell(cell)
        return outputs, (hidden, cell)

class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):
        super().__init__()
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)
        self.fc = nn.Linear(hid_dim, output_dim)
        
    def forward(self, trg, hidden):
        embedded = self.embedding(trg)
        output, (hidden, cell) = self.rnn(embedded, hidden)
        prediction = self.fc(output)
        return prediction

class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder
        
    def forward(self, src, trg):
        _, (hidden, cell) = self.encoder(src)
        output = self.decoder(trg, (hidden, cell))
        return output

# 超参数
ENC_EMB_DIM = 256
ENC_HID_DIM = 512  # 实际每个方向256，合并后512
ENC_LAYERS = 2
ENC_DROPOUT = 0.5

DEC_EMB_DIM = 256
DEC_HID_DIM = 512
DEC_LAYERS = 2
DEC_DROPOUT = 0.5

encoder = Encoder(len(src_vocab), ENC_EMB_DIM, ENC_HID_DIM//2, ENC_LAYERS, ENC_DROPOUT)
decoder = Decoder(len(trg_vocab), DEC_EMB_DIM, DEC_HID_DIM, DEC_LAYERS, DEC_DROPOUT)
model = Seq2Seq(encoder, decoder).to(device)

# 训练函数
def train(model, iterator, optimizer, criterion):
    model.train()
    epoch_loss = 0
    for batch in iterator:
        src = batch['src']
        trg = batch['trg']
        optimizer.zero_grad()
        output = model(src, trg[:-1])  # [seq_len, batch, vocab]
        loss = criterion(output.view(-1, output.shape[-1]), trg[1:].view(-1))
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)
        optimizer.step()
        epoch_loss += loss.item()
    return epoch_loss / len(iterator)

# 验证函数
def evaluate(model, iterator, criterion):
    model.eval()
    epoch_loss = 0
    with torch.no_grad():
        for batch in iterator:
            src = batch['src']
            trg = batch['trg']
            output = model(src, trg[:-1])
            loss = criterion(output.view(-1, output.shape[-1]), trg[1:].view(-1))
            epoch_loss += loss.item()
    return epoch_loss / len(iterator)

# 训练循环
optimizer = torch.optim.Adam(model.parameters())
criterion = nn.CrossEntropyLoss(ignore_index=0)
N_EPOCHS = 10
best_loss = float('inf')


train_losses = []
valid_losses = []
for epoch in range(N_EPOCHS):
    start_time = time.time()
    train_loss = train(model, train_loader, optimizer, criterion)
    valid_loss = evaluate(model, val_loader, criterion)
    end_time = time.time()
    train_losses.append(train_loss)
    valid_losses.append(valid_loss)
    
    mins, secs = divmod(end_time - start_time, 60)
    print(f'Epoch: {epoch+1:02} | Time: {mins:.0f}m {secs:.0f}s')
    print(f'\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')
    
    if valid_loss < best_loss:
        best_loss = valid_loss
        torch.save(model.state_dict(), 'rnn_seq2seq-best.pt')

# BLEU评估
def evaluate_bleu(model, loader, trg_vocab, max_len=50):
    model.eval()
    trg_list = []
    pred_list = []
    idx_to_word = {v:k for k,v in trg_vocab.items()}
    
    with torch.no_grad():
        for batch in loader:
            src = batch['src']
            trg = batch['trg']
            output = model(src, trg[:-1])
            preds = output.argmax(-1).transpose(0,1)
            
            for i in range(preds.shape[0]):
                pred = [idx_to_word.get(idx.item(), '<unk>') for idx in preds[i] if idx != 0]
                pred = [w for w in pred if w not in ['<sos>', '<eos>']]
                pred_list.append(pred)
                
                real = [idx_to_word.get(idx.item(), '<unk>') for idx in trg[1:,i] if idx != 0]
                real = [w for w in real if w not in ['<sos>', '<eos>']]
                trg_list.append([real])
    
    return corpus_bleu(trg_list, pred_list, weights=(0.25,0.25,0.25,0.25),
                      smoothing_function=SmoothingFunction().method1)

bleu = evaluate_bleu(model, val_loader, trg_vocab)
print(f'BLEU-4 Score: {bleu*100:.2f}')

# 绘制曲线
plt.figure(figsize=(10,6))
plt.plot(train_losses, label='Training Loss')
plt.plot(valid_losses, label='Validation Loss')
plt.title('Training and Validation Loss Curves')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.savefig('rnn_loss_curves.png')  # 保存图片
plt.show()
